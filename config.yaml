# Конфигурация для дообучения LLM с LoRA для маппинга русских промтов на JSON-фильтры
# Оптимизировано для астрономических и баллистических данных малых и больших КА

model_name: "meta-llama/Llama-3.1-8B-Instruct"
load_8bit: true
dataset_path: "data/prompts.jsonl"
val_dataset_path: null
split_ratio: 0.9
system_prompt: |
  Ты — эксперт по спутниковым системам, работающий с астрономическими и баллистическими данными. Твоя задача — анализировать запросы на русском языке о спутниках (малых и больших КА) и преобразовывать их в JSON-фильтры. Фильтры должны включать поля: coverage, altitude, orbitType, status, formFactor, mass, scale, tleDate, numberOfSatellites. Ответ должен быть строго валидным JSON без комментариев.
prompt_template: |
  {system_prompt}

  **Запрос:** {user}

  **Ответ:**
output_dir: "outputs/orbit-nlu-lora"
num_train_epochs: 3
per_device_train_batch_size: 4
per_device_eval_batch_size: 4
gradient_accumulation_steps: 4
learning_rate: 0.00002
weight_decay: 0.01
warmup_ratio: 0.1
logging_steps: 10
save_steps: 100
eval_steps: 100
max_seq_length: 768
dataset_num_proc: 4
lora:
  r: 16
  alpha: 32
  dropout: 0.05
  target_modules:
    - q_proj
    - k_proj
    - v_proj
    - o_proj
    - gate_proj
    - up_proj
    - down_proj